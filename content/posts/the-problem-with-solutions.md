---
title: The problem with solutions
date: 2025-12-14T08:58:10+05:30
draft: false
tags: ["society","culture","psychology"]
categories: ["Our Society"]
---
We see a lot of debate around AI these days. The reason for many of these debates is the multiple studies of people outsourcing more and more of their thinking to AI and their decline in cognitive skills. Another completely unrelated trending topic these days is the miracle weight loss drug Ozempic, which was originally created for patients with type II diabetes and is exploding in popularity and is being marketed as an easy weight loss drug. I am no expert on Ozempic, but based on what I have read, it suppresses hunger leading to less food consumption and drastic weight loss. These seemingly unrelated trending topics highlight something very core in human experience, and they are much more related to each other than they might seem at first glance. So let's discuss these issues in a generalized way in much more detail.  

Both AI and Ozempic, or any other product/innovation/service/work that we do, are some kind of solution to a problem. The problem can be known or unknown, cosmetic or structural. It can range from anywhere between mild annoyance to life-threatening. But essentially, almost everything we see around us is a solution. The solutions can be categorized broadly based on what they fix. Some solutions fix the root cause of the problem, while others just address the effects or symptoms caused by the problem. For example, something like vaccines, at least in theory, try to fix the root cause. On the other hand, something like a wheelchair tries to fix the symptoms. If a person is fully/partially paralyzed and is unable to walk, a wheelchair solves the walking problem, which is the effect and not the actual paralysis that caused the walking problem. I will refer to the second kind of solutions as *"symptomatic fixes"* for the rest of this article. Usually, root cause fixes provide resolution to a problem, while symptomatic fixes provide an amelioration of the problem. On a side note, it is important to treat these categories not as a binary, but as a spectrum. One solution can fix the root cause in some cases and the symptoms in others. For this article, we are much more interested in symptomatic fixes rather than root cause fixes.  

The symptomatic fixes can be further categorized into two types. Let's refer to the first type as *"addictive fixes"* ("addictive" is not meant in the conventional sense of the word, we will discuss the choice of this word in much more detail in a later blog post). These are solutions that make the person fully dependent on the solution similar to the wheelchair example we discussed. The second type, *"helper fixes"*, are solutions that help the person fix the root cause of the problem themselves. These solutions act as a smooth transition between the problem and the solution. Since we used the wheelchair example earlier, a walking stick fits as a great example for this category. A walking stick is usually used to help a person walk better, but it doesn't make the person dependent on it. It is a temporary solution that helps the person regain their balance eventually (although that is not the case always, that's not the point of the example). Another example, a broken bone mends itself, a plaster just helps the bone to mend faster.  

Now that we have the fundamentals out of the way, we can address the AI issue. You see, so much of the debate around AI is basically some version of the debate "whether AI is an addictive fix or a helper fix". To figure that out, we will have to look at what is the "problem" that AI is trying to solve. This question seems absurd to me, because AI does not solve one specific problem. It is a tool that can be used to solve a range of different problems ranging from writing emails to automation to medical research to military applications. It has applications in almost every field imaginable. So context matters here. To evaluate whether we are using AI as an addictive fix or a helper fix, we will have to look at the problem we are trying to fix, on an individual level. If we are using AI to write emails, and we ourselves are unable to write emails, then AI is an addictive fix in that context. If we are using AI to do tasks that we ourselves can do easily, we know the fundamentals, but we do it much more quickly and efficiently with AI, then it is a helper fix.  

Similar is the case with a drug like Ozempic. Many Ozempic users have reported that they gained all the weight that they lost when they stopped injecting it. Again, this is not medical advice and I am not an expert, but it seems to me that Ozempic is an addictive fix. Now, it is important to not fall into the trap of labelling addictive fixes as "bad" and helper fixes as "good". If an addictive fix is easily and readily available everywhere, it is debatable whether it is a good or bad fix. Also, a wheelchair is an addictive fix, but also a "good" fix in most cases. Similarly, Ozempic might be a "good" addictive fix for severely obese or type II diabetic people.  

You might have noticed that this is a general trend and not specific to AI or Ozempic. All the progress humanity has made till date has given us tools that can be either addictive fixes or helper fixes based on how they are used. Writing was a way to preserve knowledge and led to a decline in oral tradition, but it also acted as a way to outsource our memory. Calculators were a way to perform complex calculations and led to us outsourcing our mental calculation. GPS was a much more accurate way to navigate, but we are losing our direction sense. Google search got us knowledge at our fingertips, so why bother to remember anything? We have been replacing many of the low-end tasks and are letting our brains solve the more abstract, high-end problems. This trend could lead to great outcomes or a big disaster, and frankly, nobody knows where we are headed.  

The main issue is that the choice of whether to use a solution as an addictive fix or a helper fix is placed in the hands of an individual rather than something systemic. We all know how the human mind works and how easy it is, psychologically, to outsource almost everything to a tool. It is much more convenient to let an AI write the complete email rather than going through the effort ourselves. Hence, it is much more likely that most of the people using these technologies will use them as addictive fixes. Since the accountability lies with us, the individuals, it is important to be aware of this and make an informed decision. Just remember, comfort is accompanied by a cost; we should always think whether we are willing to bear that cost or not.  

Thanks for reading till the end, see you next time!